{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set notebook to use only one GPU\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfa4ddf",
   "metadata": {},
   "source": [
    "# Results Analysis\n",
    "\n",
    "Analyse results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8eac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_functions import *\n",
    "from models_bachelors import *\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# mcdropconnect = {'lockbox': {'labels': 0,\n",
    "#                              'preds': 0},\n",
    "#                  'test':    {'labels': 0,\n",
    "#                              'preds': 0}}\n",
    "# mcdropout = {'lockbox': {'labels': 0,\n",
    "#                              'preds': 0},\n",
    "#                  'test':    {'labels': 0,\n",
    "#                              'preds': 0}}\n",
    "standard = {'lockbox': {'labels': 0,\n",
    "                             'preds': 0},\n",
    "                 'test':    {'labels': 0,\n",
    "                             'preds': 0}}\n",
    "\n",
    "# # Both are dicts with keys: 'lockbox_preds_lst' and 'preds_lst'. With\n",
    "# with h5py.File('mcdropconnect/predictions_mcdropconnect.h5', 'r') as file: \n",
    "#     for group in file.keys():\n",
    "#         for dset in file[group].keys():\n",
    "#             mcdropconnect[dset][group] = file[group][dset][()]        # Get dataset as a numpy array. Yes, I know, the order is reversed...\n",
    "\n",
    "# # Both are dicts with keys: 'lockbox_preds_lst' and 'preds_lst'. With\n",
    "# with h5py.File('mcdropout/predictions_mcdropout.h5', 'r') as file: \n",
    "#     for group in file.keys():\n",
    "#         for dset in file[group].keys():\n",
    "#             mcdropout[dset][group] = file[group][dset][()]        # Get dataset as a numpy array. Yes, I know, the order is reversed...\n",
    "            \n",
    "            \n",
    "# Both are dicts with keys: 'lockbox_preds_lst' and 'preds_lst'. With\n",
    "with h5py.File('predictions_standard.h5', 'r') as file: \n",
    "    for group in file.keys():\n",
    "        for dset in file[group].keys():\n",
    "            standard[dset][group] = file[group][dset][()]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886bdfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(0.2, 'mcdropout')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d765c1",
   "metadata": {},
   "source": [
    "# Rejection use case\n",
    "Make the following graphs:\n",
    "- Distribution of Average normalised predictive entropy for incorrect and correct predictions per test subject and lockbox per method. \n",
    "- Accuracy confidence plots for both methods on test and lockbox set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c88f768",
   "metadata": {},
   "source": [
    "## Average normalised predictive entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c790b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg predictive entropy on test set for both methods\n",
    "# acc_mcdropout = []\n",
    "# acc_mcdropconnect = []\n",
    "acc_standard = []\n",
    "\n",
    "# methods = {'mcdropconnect': mcdropconnect, 'mcdropout':mcdropout, 'standard': standard}\n",
    "methods = {'standard': standard}\n",
    "\n",
    "for name, method in methods.items():\n",
    "    entropy = predictive_uncertainty(method['test']['preds'])    # shape: (9,576)\n",
    "    Y_true = method['test']['labels']    # shape: (9,576,4)\n",
    "    # corrects = np.argmax(Y_true, axis=-1) == np.argmax(method['test']['preds'], axis=-1)    # axis -1 if (9,576,4). Also get corrects across ALL subjects\n",
    "    # entropy_correct = entropy[corrects]\n",
    "    # entropy_wrong = entropy[~corrects]\n",
    "    trues = np.argmax(Y_true, axis=-1)\n",
    "    preds = np.argmax(method['test']['preds'], axis=-1)\n",
    "    # # For distribution plots of predictive entropy\n",
    "    # hist_data = [entropy_correct, entropy_wrong]\n",
    "    # group_labels = ['Correct', 'Incorrect']\n",
    "    # fig = ff.create_distplot(hist_data, group_labels, bin_size=.05)\n",
    "    # fig.show()\n",
    "    fig = make_subplots(rows=3,cols=3, subplot_titles=[f'Subj.{x}' for x in range(0,9)])\n",
    "    for r in range(1,4):\n",
    "        for col in range(1,4):\n",
    "            # World's most convoluted formula for finding out the cell number istg\n",
    "            subj_id = (3 * r) - 4 + col\n",
    "            corrects = np.argmax(Y_true[subj_id], axis=-1) == np.argmax(method['test']['preds'][subj_id], axis=-1)\n",
    "            entropy_correct = entropy[subj_id][corrects]\n",
    "            entropy_wrong = entropy[subj_id][~corrects]\n",
    "            hist_data = [entropy_correct, entropy_wrong]\n",
    "            group_labels = ['Corr.', 'Incorr.']\n",
    "            sub = ff.create_distplot(hist_data, group_labels, bin_size=0.05)\n",
    "            for trace in sub.select_traces(3):\n",
    "                fig.add_trace(trace, row=r, col=col)\n",
    "            for trace in sub.select_traces(2):\n",
    "                fig.add_trace(trace, row=r, col=col)\n",
    "\n",
    "    fig.show()\n",
    "    for idx, subject in enumerate(trues):\n",
    "        acc = accuracy_score(y_true=subject, y_pred=preds[idx], normalize=True)\n",
    "        if name == 'mcdropconnect':\n",
    "            acc_mcdropconnect.append(acc)\n",
    "        elif name == 'mcdropout':\n",
    "            acc_mcdropout.append(acc)\n",
    "        else:\n",
    "            acc_standard.append(acc)\n",
    "\n",
    "print(f'acc_mcdropconnect:{np.mean(acc_mcdropconnect)}')\n",
    "print(f'acc_mcdropout:{np.mean(acc_mcdropout)}')\n",
    "print(f'acc_std:{np.mean(acc_standard)}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I wanna see what entropy is like for a standard model\n",
    "entropy = uncertainty(Y_preds)\n",
    "corrects = np.argmax(Y_true, axis=1) == np.argmax(Y_preds, axis=1)\n",
    "entropy_correct = entropy_preds[corrects]\n",
    "entropy_wrong = entropy_preds[~corrects]\n",
    "\n",
    "# Combined distribution of entropy for correct and incorrect predictions\n",
    "hist_data = [entropy_correct, entropy_wrong]\n",
    "group_labels = ['Correct', 'Incorrect']\n",
    "\n",
    "fig = ff.create_distplot(hist_data, group_labels, bin_size=.2)\n",
    "fig.show()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
