{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbfa4ddf",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Generate and save Y_pred for both methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f82b0ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# Set notebook to use only one GPU\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da8eac33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keras Uncertainty will use standalone Keras backend"
     ]
    }
   ],
   "source": [
    "from file_functions import *\n",
    "from models_bachelors import *\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "from keras_uncertainty.models import StochasticClassifier\n",
    "\n",
    "dataset = load('all_subject_runs')\n",
    "loaded_inputs = dataset['inputs']\n",
    "loaded_targets = dataset['targets']\n",
    "'''\n",
    "Loads a dictionary with 2 keys: 'inputs', 'targets'. \n",
    "Both keys have ndarray containing inputs and targets\n",
    "of 9 subjects separated by subject.\n",
    "'''\n",
    "lockbox = load('lockbox')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2043e2",
   "metadata": {},
   "source": [
    "# To-do:\n",
    "\n",
    "This code was originally intended to save both methods predictions. But MCDropout had to undergo training again because turns out it was actually MCDropConnect being trained ðŸ’€ðŸ’€ðŸ’€. So now the code only works when methods has a single element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34108bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcdropout {'preds_lst': [], 'lockbox_preds_lst': []}\n",
      "mcdropconnect {'preds_lst': [], 'lockbox_preds_lst': []}\n"
     ]
    }
   ],
   "source": [
    "predictions = {'mcdropout': {'preds_lst': [], 'lockbox_preds_lst': []},\n",
    "                'mcdropconnect': {'preds_lst': [], 'lockbox_preds_lst': []}\n",
    "              }\n",
    "\n",
    "for method, values in predictions.items():\n",
    "    wts_directory = f'{method}/weights'\n",
    "    # For each subject, get Y_preds for the test subject, and also get the \n",
    "    # Y_preds for the lockboxed data. Then save\n",
    "    # Y preds for each subject would be shape (456, 4)\n",
    "    for subject_id in range(1, 9):\n",
    "        X_test = loaded_inputs[subject_id]\n",
    "        Y_test = loaded_targets[subject_id]\n",
    "        wts_path = checkpoint_path = f'{wts_directory}/test_subject_{subject_id}.ckpt'\n",
    "        model = create_model(method=method, drop_rates=0.2)\n",
    "        model.load_weights(wts_path)\n",
    "        # Get Y_preds for test subject\n",
    "        if method != 'standard':\n",
    "            model = StochasticClassifier(model)\n",
    "            Y_preds = model(X_test, num_samples=50)\n",
    "            # Get lockboxed Y_preds for test subject\n",
    "            lockbox_Y_preds = model(lockbox['inputs'][subject_id], num_samples=50)\n",
    "        else:\n",
    "            Y_preds = model.predict(X_test)\n",
    "            # Get lockboxed Y_preds for test subject\n",
    "            lockbox_Y_preds = model(lockbox['inputs'][subject_id])\n",
    "\n",
    "        '''\n",
    "          Must append Y_true for both cases too!\n",
    "        '''\n",
    "        values['preds_lst'].append(Y_preds)\n",
    "        values['lockbox_preds_lst'].append(lockbox_Y_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "becb35aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object dtype dtype('O') has no native HDF5 equivalent",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pmanivannan/bsc-thesis/Testing.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576f726b73746174696f6e227d/home/pmanivannan/bsc-thesis/Testing.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     methods[name][\u001b[39m'\u001b[39m\u001b[39mpreds_lst\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(preds_lst)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576f726b73746174696f6e227d/home/pmanivannan/bsc-thesis/Testing.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     methods[name][\u001b[39m'\u001b[39m\u001b[39mlockbox_preds_lst\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(lockbox_preds_lst)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576f726b73746174696f6e227d/home/pmanivannan/bsc-thesis/Testing.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m save(\u001b[39m'\u001b[39;49m\u001b[39mpredictions\u001b[39;49m\u001b[39m'\u001b[39;49m, methods)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576f726b73746174696f6e227d/home/pmanivannan/bsc-thesis/Testing.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Save Y_preds and lockboxed Y_preds to file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576f726b73746174696f6e227d/home/pmanivannan/bsc-thesis/Testing.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# save('predictions', {'y_preds': Y_preds, 'lockbox_y_preds': lockbox_Y_preds})\u001b[39;00m\n",
      "File \u001b[0;32m~/bsc-thesis/file_functions.py:18\u001b[0m, in \u001b[0;36msave\u001b[0;34m(filename, dict)\u001b[0m\n\u001b[1;32m     16\u001b[0m file \u001b[39m=\u001b[39m h5py\u001b[39m.\u001b[39mFile(filename \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mdict\u001b[39m:\n\u001b[0;32m---> 18\u001b[0m    file\u001b[39m.\u001b[39;49mcreate_dataset(name, data\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m[name])\n\u001b[1;32m     19\u001b[0m file\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/h5py/_hl/group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    180\u001b[0m         parent_path, name \u001b[39m=\u001b[39m name\u001b[39m.\u001b[39mrsplit(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    181\u001b[0m         group \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 183\u001b[0m dsid \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmake_new_dset(group, shape, dtype, data, name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    184\u001b[0m dset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mDataset(dsid)\n\u001b[1;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m dset\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/h5py/_hl/dataset.py:86\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m         dtype \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[0;32m---> 86\u001b[0m     tid \u001b[39m=\u001b[39m h5t\u001b[39m.\u001b[39;49mpy_create(dtype, logical\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     88\u001b[0m \u001b[39m# Legacy\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m((compression, shuffle, fletcher32, maxshape, scaleoffset)) \u001b[39mand\u001b[39;00m chunks \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32mh5py/h5t.pyx:1664\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:1688\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:1748\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object dtype dtype('O') has no native HDF5 equivalent"
     ]
    }
   ],
   "source": [
    "for method, values in predictions:\n",
    "    values['preds_lst'] = np.array(np.array(values['preds_lst']))\n",
    "    values['lockbox_preds_lst'] = np.array(values['lockbox_preds_lst'])\n",
    "\n",
    "save('predictions_mcdropout', predictions['mcdropout'])\n",
    "save('predictions_mcdropconnect', predictions['mcdropconnect'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d765c1",
   "metadata": {},
   "source": [
    "# Useful code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # I wanna see what entropy is like for a standard model\n",
    "    entropy = uncertainty(Y_preds)\n",
    "    corrects = np.argmax(Y_true, axis=1) == np.argmax(Y_preds, axis=1)\n",
    "    entropy_correct = entropy_preds[corrects]\n",
    "    entropy_wrong = entropy_preds[~corrects]\n",
    "\n",
    "    # Combined distribution of entropy for correct and incorrect predictions\n",
    "    hist_data = [entropy_correct, entropy_wrong]\n",
    "    group_labels = ['Correct', 'Incorrect']\n",
    "\n",
    "    fig = ff.create_distplot(hist_data, group_labels, bin_size=.2)\n",
    "    fig.show()\n",
    "             \n",
    "\n",
    "entropy_correct = entropy_preds[corrects]\n",
    "entropy_wrong = entropy_preds[~corrects]\n",
    "\n",
    "# Combined distribution of entropy for correct and incorrect predictions\n",
    "hist_data = [entropy_correct, entropy_wrong]\n",
    "group_labels = ['Correct', 'Incorrect']\n",
    "\n",
    "fig = ff.create_distplot(hist_data, group_labels, bin_size=.2)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
